from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch
import logging

app = Flask(__name__)
CORS(app)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MyAIAssistant:
    def __init__(self):
        self.model_loaded = False
        self.model = None
        self.tokenizer = None
        
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ)"""
        try:
            logger.info("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º AI –º–æ–¥–µ–ª—å...")
            
            # –í–∞—Ä–∏–∞–Ω—Ç 1: –ë—ã—Å—Ç—Ä–∞—è –ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
            self.tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-medium")
            self.model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-medium")
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º pipeline –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
            self.chat_pipeline = pipeline(
                "text-generation",
                model="microsoft/DialoGPT-medium",
                tokenizer=self.tokenizer,
                max_length=500
            )
            
            self.model_loaded = True
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

ai_assistant = MyAIAssistant()

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ AI
SYSTEM_PROMPT = """–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ DeepHelper. –¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é, –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ –∏ –¥—Ä—É–≥–∏–º —Ç–µ–º–∞–º. –ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º, –ø–æ–ª–µ–∑–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º –≤ –æ—Ç–≤–µ—Ç–∞—Ö."""

def generate_response(user_message):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    if not ai_assistant.model_loaded:
        ai_assistant.load_model()
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        prompt = f"{SYSTEM_PROMPT}\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}\n–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        with torch.no_grad():
            inputs = ai_assistant.tokenizer.encode(prompt, return_tensors='pt')
            outputs = ai_assistant.model.generate(
                inputs,
                max_length=len(inputs[0]) + 200,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
                num_return_sequences=1,
                temperature=0.7,
                do_sample=True,
                pad_token_id=ai_assistant.tokenizer.eos_token_id,
                repetition_penalty=1.2
            )
            
        response = ai_assistant.tokenizer.decode(outputs[0], skip_special_tokens=True)
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        response = response.split("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:")[-1].strip()
        
        return response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        user_message = data.get('message', '')
        
        if not user_message:
            return jsonify({'error': '–ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ'}), 400
        
        logger.info(f"üì® –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_message}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = generate_response(user_message)
        
        logger.info(f"üì§ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {response[:100]}...")
        
        return jsonify({
            'response': response,
            'status': 'success'
        })
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ /api/chat: {e}")
        return jsonify({'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'}), 500

@app.route('/api/status')
def status():
    return jsonify({
        'status': 'online',
        'model_loaded': ai_assistant.model_loaded,
        'name': 'DeepHelper AI'
    })

if __name__ == '__main__':
    logger.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º AI —Å–µ—Ä–≤–µ—Ä...")
    app.run(host='0.0.0.0', port=5000, debug=True)
